{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOAMLzFgHHAJSvEnv1KGC+v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Configura tokeniza√ß√£o üî£"],"metadata":{"id":"tXf1cakhGfg0"}},{"cell_type":"code","source":["pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aq51a60m8iG4","executionInfo":{"status":"ok","timestamp":1739716365950,"user_tz":180,"elapsed":12257,"user":{"displayName":"Bruno Berto","userId":"06526414926027817953"}},"outputId":"6466ddc4-f243-4182-af11-5e740f53faf1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tiktoken\n","  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n","Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken\n","Successfully installed tiktoken-0.9.0\n"]}]},{"cell_type":"code","source":["import tiktoken\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","# Fun√ß√£o texto -> token\n","def text_to_token_ids(text, tokenizer):\n","    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n","    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n","    return encoded_tensor\n","\n","# Fun√ß√£o token -> texto\n","def token_ids_to_text(token_ids, tokenizer):\n","    flat = token_ids.squeeze(0)\n","    return tokenizer.decode(flat.tolist())"],"metadata":{"id":"xcuvORDZ_aWy","executionInfo":{"status":"ok","timestamp":1739716370202,"user_tz":180,"elapsed":3062,"user":{"displayName":"Bruno Berto","userId":"06526414926027817953"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Baixa e configura modelo *GPT* (livro base) ‚Ü™"],"metadata":{"id":"f5svMKYcDFt1"}},{"cell_type":"markdown","source":["Baixa arquivos relacionados ao modelo do livro base"],"metadata":{"id":"g8vZ0oaXDN7D"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"BH2sYMzK2HAh","executionInfo":{"status":"ok","timestamp":1739716374363,"user_tz":180,"elapsed":1157,"user":{"displayName":"Bruno Berto","userId":"06526414926027817953"}}},"outputs":[],"source":["import os\n","\n","# Baixa o arquivo gpt_download.py do livro\n","if not os.path.exists(\"gpt_download.py\"):\n","  url = \"https://raw.githubusercontent.com/rasbt/\"\\\n","        \"LLMs-from-scratch/main/ch05/\"\\\n","        \"01_main-chapter-code/gpt_download.py\"\n","  cmd = ! wget {url}\n","\n","# Baixa o modelo do GPT do livro\n","if not os.path.exists(\"previous_chapters.py\"):\n","  url = \"https://raw.githubusercontent.com/rasbt/\"\\\n","        \"LLMs-from-scratch/main/ch05/\"\\\n","        \"01_main-chapter-code/previous_chapters.py\"\n","  cmd = ! wget {url}\n"]},{"cell_type":"markdown","source":["Baixa modelo GPT2"],"metadata":{"id":"dcnPu90ADgZ-"}},{"cell_type":"code","source":["from gpt_download import download_and_load_gpt2\n","\n","# Baixa modelo\n","settings, params = download_and_load_gpt2(\n","    model_size=\"124M\", models_dir=\"gpt2\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrGXr7EV3xhi","executionInfo":{"status":"ok","timestamp":1739716415857,"user_tz":180,"elapsed":38787,"user":{"displayName":"Bruno Berto","userId":"06526414926027817953"}},"outputId":"7d913fc6-f833-430a-c1a4-f8d7d4314080"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["checkpoint: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77.0/77.0 [00:00<00:00, 138kiB/s]\n","encoder.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.04M/1.04M [00:00<00:00, 2.47MiB/s]\n","hparams.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90.0/90.0 [00:00<00:00, 78.8kiB/s]\n","model.ckpt.data-00000-of-00001: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 498M/498M [00:29<00:00, 16.8MiB/s]\n","model.ckpt.index: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.21k/5.21k [00:00<00:00, 8.15MiB/s]\n","model.ckpt.meta: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 471k/471k [00:00<00:00, 1.72MiB/s]\n","vocab.bpe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 456k/456k [00:00<00:00, 1.79MiB/s]\n"]}]},{"cell_type":"markdown","source":["Configura√ß√£o do modelo"],"metadata":{"id":"35NKO_IRHsOh"}},{"cell_type":"code","source":["import torch\n","from previous_chapters import GPTModel\n","\n","GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257,   # Tamanho do vocabul√°rio\n","    \"context_length\": 256, # Tamanho do contexto reduzido (original: 1024)\n","    \"emb_dim\": 768,        # Dimens√£o do embedding\n","    \"n_heads\": 12,         # N√∫mero de cabe√ßas de aten√ß√£o\n","    \"n_layers\": 12,        # N√∫mero de camadas\n","    \"drop_rate\": 0.1,      # Taxa de dropout\n","    \"qkv_bias\": False      # Vi√©s de consulta-chave-valor\n","}\n","\n","# Configura√ß√£o de modelos dispon√≠veis\n","model_configs = {\n","    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n","    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n","    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n","    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n","}\n","\n","# Termina de configura modelo (no nosso caso o \"gpt2-small (124M)\")\n","model_name = \"gpt2-small (124M)\"\n","NEW_CONFIG = GPT_CONFIG_124M\n","NEW_CONFIG.update(model_configs[model_name])\n","NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n","\n","gpt = GPTModel(NEW_CONFIG)\n","gpt.eval();"],"metadata":{"id":"z72D4NIN5XSg","executionInfo":{"status":"ok","timestamp":1739716426263,"user_tz":180,"elapsed":7110,"user":{"displayName":"Bruno Berto","userId":"06526414926027817953"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Carrega pesos do GPT com os devidos ajustes"],"metadata":{"id":"QzhcxS1ZFT5P"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Fun√ß√£o auxiliar de ajuste de tensores\n","def assign(left, right):\n","    if left.shape != right.shape:\n","        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n","    return torch.nn.Parameter(torch.tensor(right))\n","\n","# Fun√ß√£o que carrega os pesos do GPT com ajustes\n","def load_weights_into_gpt(gpt, params):\n","    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n","    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n","\n","    for b in range(len(params[\"blocks\"])):\n","        q_w, k_w, v_w = np.split(\n","            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n","        gpt.trf_blocks[b].att.W_query.weight = assign(\n","            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n","        gpt.trf_blocks[b].att.W_key.weight = assign(\n","            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n","        gpt.trf_blocks[b].att.W_value.weight = assign(\n","            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n","\n","        q_b, k_b, v_b = np.split(\n","            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n","        gpt.trf_blocks[b].att.W_query.bias = assign(\n","            gpt.trf_blocks[b].att.W_query.bias, q_b)\n","        gpt.trf_blocks[b].att.W_key.bias = assign(\n","            gpt.trf_blocks[b].att.W_key.bias, k_b)\n","        gpt.trf_blocks[b].att.W_value.bias = assign(\n","            gpt.trf_blocks[b].att.W_value.bias, v_b)\n","\n","        gpt.trf_blocks[b].att.out_proj.weight = assign(\n","            gpt.trf_blocks[b].att.out_proj.weight,\n","            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n","        gpt.trf_blocks[b].att.out_proj.bias = assign(\n","            gpt.trf_blocks[b].att.out_proj.bias,\n","            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n","\n","        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n","            gpt.trf_blocks[b].ff.layers[0].weight,\n","            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n","        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n","            gpt.trf_blocks[b].ff.layers[0].bias,\n","            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n","        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n","            gpt.trf_blocks[b].ff.layers[2].weight,\n","            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n","        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n","            gpt.trf_blocks[b].ff.layers[2].bias,\n","            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n","\n","        gpt.trf_blocks[b].norm1.scale = assign(\n","            gpt.trf_blocks[b].norm1.scale,\n","            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n","        gpt.trf_blocks[b].norm1.shift = assign(\n","            gpt.trf_blocks[b].norm1.shift,\n","            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n","        gpt.trf_blocks[b].norm2.scale = assign(\n","            gpt.trf_blocks[b].norm2.scale,\n","            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n","        gpt.trf_blocks[b].norm2.shift = assign(\n","            gpt.trf_blocks[b].norm2.shift,\n","            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n","\n","    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n","    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n","    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n","\n","# Carrega os pesos\n","load_weights_into_gpt(gpt, params)\n","\n","# Usa o cuda se poss√≠vel (otimiza√ß√£o)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","gpt.to(device);"],"metadata":{"id":"T1mlheJc-EMt","executionInfo":{"status":"ok","timestamp":1739716437074,"user_tz":180,"elapsed":1079,"user":{"displayName":"Bruno Berto","userId":"06526414926027817953"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Gera√ß√£o de texto üñä"],"metadata":{"id":"JVnfuVzqHcC1"}},{"cell_type":"code","source":["# Fun√ß√£o de gera√ß√£o de texto\n","def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n","    for _ in range(max_new_tokens):\n","        idx_cond = idx[:, -context_size:]\n","        with torch.no_grad():\n","            logits = model(idx_cond)\n","        logits = logits[:, -1, :]\n","\n","        # Filtra os logits com amostragem top_k\n","        if top_k is not None:\n","            # Mant√©m apenas os top_k valores\n","            top_logits, _ = torch.topk(logits, top_k)\n","            min_val = top_logits[:, -1]\n","            logits = torch.where(logits < min_val,\n","                          torch.tensor(float(\"-inf\")).to(logits.device), logits)\n","\n","        # Aplica o escalonamento de temperatura\n","        if temperature > 0.0:\n","            logits = logits / temperature\n","\n","            # Aplica softmax para obter as probabilidades\n","            probs = torch.softmax(logits, dim=-1)\n","\n","            # Amostra a partir da distribui√ß√£o\n","            idx_next = torch.multinomial(probs, num_samples=1)\n","\n","        # Caso contr√°rio, o mesmo de antes: obt√©m o idx da entrada do\n","        # vocabul√°rio com o valor de logits mais alto\n","        else:\n","            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n","\n","        # Para de gerar precocemente se o token de fim de sequ√™ncia for\n","        # encontrado e eos_id for especificado\n","        if idx_next == eos_id:\n","            break\n","\n","        # Mesmo de antes: anexa o √≠ndice amostrado √† sequ√™ncia em execu√ß√£o\n","        idx = torch.cat((idx, idx_next), dim=1)\n","\n","    return idx"],"metadata":{"id":"M4r1ak9L-3lN","executionInfo":{"status":"ok","timestamp":1739716440847,"user_tz":180,"elapsed":251,"user":{"displayName":"Bruno Berto","userId":"06526414926027817953"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Gera texto"],"metadata":{"id":"afYhsubfH3jP"}},{"cell_type":"code","source":["# Seed escolhida\n","torch.manual_seed(78)\n","\n","token_ids = generate(\n","    model=gpt,\n","    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n","    max_new_tokens=50,\n","    context_size=NEW_CONFIG[\"context_length\"],\n","    top_k=50,\n","    temperature=1.5\n",")\n","\n","print(f\"Texto de sa√≠da:\\n\\n{token_ids_to_text(token_ids, tokenizer)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-TuG04D-s-6","executionInfo":{"status":"ok","timestamp":1739716458271,"user_tz":180,"elapsed":12916,"user":{"displayName":"Bruno Berto","userId":"06526414926027817953"}},"outputId":"950f05e3-c9af-47c4-d3a1-accd2adf4444"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Texto de sa√≠da:\n","\n","Every effort moves you\n","\n","as one, like God and earth\n","\n","as waters, on\n","\n","a plane to move. Each\n","\n","spirit makes every motion\n","\n","the entire physical force of existence. No\n","\n","place is the centre where the movements unfold -\n"]}]}]}